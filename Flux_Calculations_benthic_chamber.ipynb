{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df3aa01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #the csv reading library\n",
    "import matplotlib.pyplot as plt #the ploting library\n",
    "import glob #to get file names\n",
    "import numpy as np\n",
    "from pandas import Series\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import cmocean.cm as cmo\n",
    "import seaborn as sns\n",
    "\n",
    "from pylab import rcParams\n",
    "from numpy import diff\n",
    "from scipy import interpolate\n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import cmocean\n",
    "import cmocean.cm as cmo\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9b5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iron = pd.read_csv('../Dissertation_projects/Data/IRON/Iron.csv', sep=',', index_col=0)\n",
    "\n",
    "#make all the spots labeled NA a nan value\n",
    "df_iron = df_iron.replace('NA', np.nan)\n",
    "df_iron = df_iron.replace('NA ', np.nan)\n",
    "\n",
    "#make all BDL a 0 \n",
    "df_iron.loc[df_iron['FeT_uM'] == 'BLD', 'FeT_uM'] = 0\n",
    "df_iron.loc[df_iron['Fe2_uM'] == 'BLD', 'Fe2_uM'] = 0\n",
    "\n",
    "# convert columns to numeric data type\n",
    "df_iron['FeT_uM'] = pd.to_numeric(df_iron['FeT_uM'], errors='coerce')\n",
    "df_iron['Fe2_uM'] = pd.to_numeric(df_iron['Fe2_uM'], errors='coerce')\n",
    "\n",
    "df_iron['FeT_uM'] = df_iron['FeT_uM'].where(pd.notna(df_iron['FeT_uM']), other=np.nan)\n",
    "df_iron['Fe2_uM'] = df_iron['Fe2_uM'].where(pd.notna(df_iron['Fe2_uM']), other=np.nan)\n",
    "\n",
    "#make all negative a 0 \n",
    "df_iron.loc[df_iron['FeT_uM'] < 0, 'FeT_uM'] = 0\n",
    "df_iron.loc[df_iron['Fe2_uM'] < 0, 'Fe2_uM'] = 0\n",
    "\n",
    "#calculate Fe +3 \n",
    "df_iron['Fe3_uM'] = df_iron['FeT_uM'] - df_iron['Fe2_uM']\n",
    "df_iron.loc[df_iron['Fe3_uM'] < 0, 'Fe3_uM'] = 0\n",
    "df_iron.loc[df_iron['Fe2_uM'] > df_iron['FeT_uM'], 'Fe3_uM'] = 0\n",
    "df_iron['Fe3_uM'] = pd.to_numeric(df_iron['Fe3_uM'], errors='coerce')\n",
    "df_iron['Fe3_uM'] = df_iron['Fe3_uM'].where(pd.notna(df_iron['Fe3_uM']), other=np.nan)\n",
    "\n",
    "#time feild \n",
    "df_iron['Fe2_Time'] = pd.to_numeric(df_iron['Fe2_Time'], errors='coerce')\n",
    "df_iron['Fe2_Time'] = df_iron['Fe2_Time'].where(pd.notna(df_iron['Fe2_Time']), other=np.nan)\n",
    "\n",
    "#time feild \n",
    "df_iron['FeT_Time'] = pd.to_numeric(df_iron['FeT_Time'], errors='coerce')\n",
    "df_iron['FeT_Time'] = df_iron['FeT_Time'].where(pd.notna(df_iron['FeT_Time']), other=np.nan)\n",
    "\n",
    "df_iron['code'] = df_iron['Location'] + '_' + df_iron['Campaign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1937dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc = pd.read_csv('../Dissertation_projects/Data/TOC/TOC_GOM.csv', sep=',', index_col=0)\n",
    "\n",
    "#make all BDL a 0 \n",
    "df_doc.loc[df_doc['NPOC_uM'] == 'BLD', 'NPOC_uM'] = 0\n",
    "df_doc.loc[df_doc['TN_uM'] == 'BLD', 'TN_uM'] = 0\n",
    "\n",
    "df_doc.loc[df_doc['NPOC_uM'] < 0, 'NPOC_uM'] = 0\n",
    "df_doc.loc[df_doc['TN_uM'] < 0, 'TN_uM'] = 0\n",
    "\n",
    "#fix date time \n",
    "df_doc['date_time'] = pd.to_datetime(df_doc['Date'])\n",
    "df_doc['Date'] = df_doc['date_time'].dt.date\n",
    "\n",
    "df_doc['NPOC_uM'] = pd.to_numeric(df_doc['NPOC_uM'], errors='coerce')\n",
    "df_doc['NPOC_uM'] = df_doc['NPOC_uM'].where(pd.notna(df_doc['NPOC_uM']), other=np.nan)\n",
    "\n",
    "df_doc['TN_uM'] = pd.to_numeric(df_doc['TN_uM'], errors='coerce')\n",
    "df_doc['TN_uM'] = df_doc['TN_uM'].where(pd.notna(df_doc['TN_uM']), other=np.nan)\n",
    "\n",
    "df_doc['Time'] = pd.to_numeric(df_doc['Time'], errors='coerce')\n",
    "df_doc['Time'] = df_doc['Time'].where(pd.notna(df_doc['Time']), other=np.nan)\n",
    "\n",
    "df_doc['code'] = df_doc['Location'] + '_' + df_doc['Campaign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e62bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nisk = pd.read_csv('../Dissertation_projects/Data/CTD/NISK_SUMS.csv', sep=',', index_col=0)\n",
    "\n",
    "# drop rows with NaN index values\n",
    "df_nisk = df_nisk[df_nisk['Sample_ID'].notna()]\n",
    "df_nisk['code'] = df_nisk['station'] + '_' + df_nisk['camp']\n",
    "\n",
    "# reformat the index to be a whole number\n",
    "df_nisk.index = df_nisk.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab3705a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Trip</th>\n",
       "      <th>Station</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Water_depth</th>\n",
       "      <th>Sample_depth</th>\n",
       "      <th>Sample_depth_units</th>\n",
       "      <th>Wavguide_Path_lengths</th>\n",
       "      <th>BC_time</th>\n",
       "      <th>BC_Chamber_vol_(L)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Waveguide_used</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Flagged</th>\n",
       "      <th>Salinity</th>\n",
       "      <th>date_time</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211901</th>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>GOM2021</td>\n",
       "      <td>St.MK</td>\n",
       "      <td>28.906820</td>\n",
       "      <td>-90.333160</td>\n",
       "      <td>16.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NISK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.223851</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>St.MK_GOM2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211902</th>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>GOM2021</td>\n",
       "      <td>St.MK</td>\n",
       "      <td>28.906820</td>\n",
       "      <td>-90.333163</td>\n",
       "      <td>16.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NISK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.183855</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>St.MK_GOM2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211903</th>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>GOM2021</td>\n",
       "      <td>St.MK</td>\n",
       "      <td>28.906660</td>\n",
       "      <td>-90.334096</td>\n",
       "      <td>16.7</td>\n",
       "      <td>14</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NISK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.505918</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>St.MK_GOM2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211904</th>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>GOM2021</td>\n",
       "      <td>St.MK</td>\n",
       "      <td>28.906660</td>\n",
       "      <td>-90.334119</td>\n",
       "      <td>16.7</td>\n",
       "      <td>14</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NISK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.486418</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>St.MK_GOM2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211905</th>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>GOM2021</td>\n",
       "      <td>St.MK</td>\n",
       "      <td>28.906531</td>\n",
       "      <td>-90.334841</td>\n",
       "      <td>16.7</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NISK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.824471</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>St.MK_GOM2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225390</th>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>GOM22SU</td>\n",
       "      <td>St.MK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>CM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RHZ</td>\n",
       "      <td>1CM CUV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.007597</td>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>St.MK_GOM22SU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225391</th>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>GOM22SU</td>\n",
       "      <td>St.MK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>CM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RHZ</td>\n",
       "      <td>1CM CUV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.007597</td>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>St.MK_GOM22SU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225392</th>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>GOM22SU</td>\n",
       "      <td>St.MK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>CM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RHZ</td>\n",
       "      <td>1CM CUV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.007597</td>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>St.MK_GOM22SU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225393</th>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>GOM22SU</td>\n",
       "      <td>St.MK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>CM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RHZ</td>\n",
       "      <td>1CM CUV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.007597</td>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>St.MK_GOM22SU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225394</th>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>GOM22SU</td>\n",
       "      <td>St.MK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46</td>\n",
       "      <td>CM</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RHZ</td>\n",
       "      <td>1CM CUV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.007597</td>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>St.MK_GOM22SU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date     Trip Station        Lat        Lon  Water_depth  \\\n",
       "Sample                                                                   \n",
       "211901  2021-07-15  GOM2021   St.MK  28.906820 -90.333160         16.7   \n",
       "211902  2021-07-15  GOM2021   St.MK  28.906820 -90.333163         16.7   \n",
       "211903  2021-07-15  GOM2021   St.MK  28.906660 -90.334096         16.7   \n",
       "211904  2021-07-15  GOM2021   St.MK  28.906660 -90.334119         16.7   \n",
       "211905  2021-07-15  GOM2021   St.MK  28.906531 -90.334841         16.7   \n",
       "...            ...      ...     ...        ...        ...          ...   \n",
       "225390  2022-07-23  GOM22SU   St.MK        NaN        NaN          NaN   \n",
       "225391  2022-07-23  GOM22SU   St.MK        NaN        NaN          NaN   \n",
       "225392  2022-07-23  GOM22SU   St.MK        NaN        NaN          NaN   \n",
       "225393  2022-07-23  GOM22SU   St.MK        NaN        NaN          NaN   \n",
       "225394  2022-07-23  GOM22SU   St.MK        NaN        NaN          NaN   \n",
       "\n",
       "       Sample_depth Sample_depth_units  Wavguide_Path_lengths  BC_time  \\\n",
       "Sample                                                                   \n",
       "211901         16.7                  M                    NaN      NaN   \n",
       "211902         16.7                  M                    NaN      NaN   \n",
       "211903           14                  M                    NaN      NaN   \n",
       "211904           14                  M                    NaN      NaN   \n",
       "211905           10                  M                    NaN      NaN   \n",
       "...             ...                ...                    ...      ...   \n",
       "225390           30                 CM                   0.01      NaN   \n",
       "225391           34                 CM                   0.01      NaN   \n",
       "225392           38                 CM                   0.01      NaN   \n",
       "225393           42                 CM                   0.01      NaN   \n",
       "225394           46                 CM                   0.01      NaN   \n",
       "\n",
       "        BC_Chamber_vol_(L)  Type Waveguide_used Notes Flagged   Salinity  \\\n",
       "Sample                                                                     \n",
       "211901                 NaN  NISK            NaN   NaN     NaN  35.223851   \n",
       "211902                 NaN  NISK            NaN   NaN     NaN  35.183855   \n",
       "211903                 NaN  NISK            NaN   NaN     NaN  34.505918   \n",
       "211904                 NaN  NISK            NaN   NaN     NaN  34.486418   \n",
       "211905                 NaN  NISK            NaN   NaN     NaN  32.824471   \n",
       "...                    ...   ...            ...   ...     ...        ...   \n",
       "225390                 NaN   RHZ        1CM CUV   NaN     NaN  36.007597   \n",
       "225391                 NaN   RHZ        1CM CUV   NaN     NaN  36.007597   \n",
       "225392                 NaN   RHZ        1CM CUV   NaN     NaN  36.007597   \n",
       "225393                 NaN   RHZ        1CM CUV   NaN     NaN  36.007597   \n",
       "225394                 NaN   RHZ        1CM CUV   NaN     NaN  36.007597   \n",
       "\n",
       "        date_time           code  \n",
       "Sample                            \n",
       "211901 2021-07-15  St.MK_GOM2021  \n",
       "211902 2021-07-15  St.MK_GOM2021  \n",
       "211903 2021-07-15  St.MK_GOM2021  \n",
       "211904 2021-07-15  St.MK_GOM2021  \n",
       "211905 2021-07-15  St.MK_GOM2021  \n",
       "...           ...            ...  \n",
       "225390 2022-07-23  St.MK_GOM22SU  \n",
       "225391 2022-07-23  St.MK_GOM22SU  \n",
       "225392 2022-07-23  St.MK_GOM22SU  \n",
       "225393 2022-07-23  St.MK_GOM22SU  \n",
       "225394 2022-07-23  St.MK_GOM22SU  \n",
       "\n",
       "[2515 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.read_csv('../Dissertation_projects/Data/meta_data.csv', sep=',', index_col=0)\n",
    "\n",
    "#fix date time \n",
    "df_meta['date_time'] = pd.to_datetime(df_meta['Date'])\n",
    "df_meta['Date'] = df_meta['date_time'].dt.date\n",
    "\n",
    "df_meta['code'] = df_meta['Station'] + '_' + df_meta['Trip']\n",
    "\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3a8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv('../Dissertation_projects/Data/CDOM/Outputs.csv', sep=',', index_col=0)\n",
    "\n",
    "df_c['Sample_idx'] = df_c.index.astype(object)\n",
    "df_meta['Sample_idx'] = df_meta.index.astype(object)\n",
    "\n",
    "df_c.index = df_c['file_id']\n",
    "\n",
    "df_cdom = df_c.merge(df_meta, on=\"Sample_idx\", how=\"left\")\n",
    "\n",
    "df_cdom.index = df_cdom['Sample_idx']\n",
    "df_cdom['Sample'] = df_cdom.index\n",
    "df_cdom.index = df_cdom['Sample']\n",
    "df_cdom = df_cdom.drop('Sample_idx', axis = 1)\n",
    "df_meta = df_meta.drop('Sample_idx', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1cf5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get BC data sets \n",
    "df_cdom_bc = df_cdom[df_cdom['Type'] == 'LANDSYR']\n",
    "df_iron_bc = df_iron[df_iron['Type'] == 'BC']\n",
    "df_doc_bc = df_doc[df_doc['Type'] == 'BC']\n",
    "\n",
    "#get PW data sets \n",
    "df_cdom_pw = df_cdom[df_cdom['Type'] == 'PW']\n",
    "df_iron_pw = df_iron[df_iron['Type'] == 'PW']\n",
    "df_doc_pw = df_doc[df_doc['Type'] == 'PW']\n",
    "\n",
    "#get WC data sets \n",
    "df_cdom_wc = df_cdom[df_cdom['Type'] == 'NISK']\n",
    "df_iron_wc = df_iron[df_iron['Type'] == 'WC']\n",
    "df_doc_wc = df_doc[df_doc['Type'] == 'WC']\n",
    "\n",
    "#get RHZ data \n",
    "df_cdom_rz = df_cdom[df_cdom['Type'] == 'RHZ']\n",
    "df_iron_rz = df_iron[df_iron['Type'].isin(['RZ', 'GBRZ'])]\n",
    "df_doc_rz = df_doc[df_doc['Type'] == 'RZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce74d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmlbr\\AppData\\Local\\Temp\\ipykernel_12332\\3227746585.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_doc_bc['Sample_idx'] = df_doc_bc.index.astype(object)\n",
      "C:\\Users\\hmlbr\\AppData\\Local\\Temp\\ipykernel_12332\\3227746585.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_doc_bc['Sample'] = df_doc_bc.index\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inputs must not be empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m df_cdom_doc \u001b[38;5;241m=\u001b[39m df_cdom_doc\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNPOC_uM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macdom_350_bc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     27\u001b[0m df_cdom_doc \u001b[38;5;241m=\u001b[39m df_cdom_doc\u001b[38;5;241m.\u001b[39mdrop(df_cdom_doc[(df_cdom_doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNPOC_uM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m|\u001b[39m (df_cdom_doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macdom_350_bc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m2\u001b[39m)]\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m---> 29\u001b[0m slope, intercept, r_value, p_value, std_err \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mlinregress(df_cdom_doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macdom_350_bc\u001b[39m\u001b[38;5;124m'\u001b[39m], df_cdom_doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNPOC_uM\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Step 3: Finding the ratio where NPOC_uM is equal to acdom_350_bc\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# slope * x + intercept = x  =>  x * (slope - 1) = -intercept  =>  x = -intercept / (slope - 1)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m x_equal \u001b[38;5;241m=\u001b[39m slope\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bugs\\Lib\\site-packages\\scipy\\stats\\_stats_mstats_common.py:154\u001b[0m, in \u001b[0;36mlinregress\u001b[1;34m(x, y, alternative)\u001b[0m\n\u001b[0;32m    151\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs must not be empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mamax(x) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mamin(x) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot calculate a linear regression \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif all x values are identical\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Inputs must not be empty."
     ]
    }
   ],
   "source": [
    "df_cdom_bc['Sample_idx'] = df_cdom_bc.index.astype(object)\n",
    "df_doc_bc['Sample_idx'] = df_doc_bc.index.astype(object)\n",
    "\n",
    "df_cdom_bc.index = df_cdom_bc['file_id']\n",
    "\n",
    "df_cdom_doc = df_cdom_bc.merge(df_doc_bc, on=\"Sample_idx\", how=\"left\")\n",
    "\n",
    "df_cdom_doc.index = df_cdom_doc['Sample_idx']\n",
    "df_cdom_doc['Sample'] = df_cdom_doc.index\n",
    "df_cdom_doc.index = df_cdom_doc['Sample']\n",
    "\n",
    "df_cdom_bc.index = df_cdom_bc['Sample_idx']\n",
    "df_cdom_bc['Sample'] = df_cdom_bc.index\n",
    "df_cdom_bc.index = df_cdom_bc['Sample']\n",
    "\n",
    "df_doc_bc.index = df_doc_bc['Sample_idx']\n",
    "df_doc_bc['Sample'] = df_doc_bc.index\n",
    "df_doc_bc.index = df_doc_bc['Sample']\n",
    "\n",
    "df_cdom_doc = df_cdom_doc.drop('Sample_idx', axis = 1)\n",
    "df_doc_bc = df_doc_bc.drop('Sample_idx', axis = 1)\n",
    "df_cdom_bc = df_cdom_bc.drop('Sample_idx', axis = 1)\n",
    "\n",
    "\n",
    "# Step 2: Conducting a linear regression\n",
    "df_cdom_doc = df_cdom_doc.dropna(subset=['NPOC_uM', 'acdom_350_bc'])\n",
    "df_cdom_doc = df_cdom_doc.drop(df_cdom_doc[(df_cdom_doc['NPOC_uM'] == 0) | (df_cdom_doc['acdom_350_bc'] >2)].index)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_cdom_doc['acdom_350_bc'], df_cdom_doc['NPOC_uM'])\n",
    "\n",
    "# Step 3: Finding the ratio where NPOC_uM is equal to acdom_350_bc\n",
    "# slope * x + intercept = x  =>  x * (slope - 1) = -intercept  =>  x = -intercept / (slope - 1)\n",
    "x_equal = slope\n",
    "x_err = std_err\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Step 1: Plotting the scatter plot\n",
    "plt.scatter(df_cdom_doc['acdom_350_bc'], df_cdom_doc['NPOC_uM'], color='blue', label='Data points')\n",
    "# Step 4: Plotting the regression line\n",
    "x_vals = df_cdom_doc['acdom_350_bc']\n",
    "y_vals = slope * x_vals + intercept\n",
    "plt.plot(x_vals, y_vals, color='red', label=f'Regression Line (y={slope:.2f}x + {intercept:.2f})')\n",
    "\n",
    "plt.xlim(0,2)\n",
    "plt.ylim(0,400)\n",
    "\n",
    "# Step 5: Annotating the plot with the calculated ratio and r-value\n",
    "plt.annotate(f'slope (NPOC:acdom) = {x_equal:.2f}', xy=(0.07, 0.9), xycoords='axes fraction')\n",
    "plt.annotate(f'R-value = {r_value:.2f}', xy=(0.1, 0.85), xycoords='axes fraction')\n",
    "\n",
    "plt.ylabel('NPOC_uM')\n",
    "plt.xlabel('acdom_350_bc')\n",
    "plt.legend()\n",
    "plt.title('Scatter plot with Linear Regression')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "x_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5e8a1",
   "metadata": {},
   "source": [
    "df_cdom_bc['Sample_idx'] = df_cdom_bc.index.astype(object)\n",
    "df_iron_bc['Sample_idx'] = df_iron_bc.index.astype(object)\n",
    "\n",
    "df_cdom_bc.index = df_cdom_bc['file_id']\n",
    "\n",
    "df_fe_cdom = df_cdom_bc.merge(df_iron_bc, on=\"Sample_idx\", how=\"left\")\n",
    "\n",
    "df_fe_cdom.index = df_fe_cdom['Sample_idx']\n",
    "df_fe_cdom['Sample'] = df_fe_cdom.index\n",
    "df_fe_cdom.index = df_fe_cdom['Sample']\n",
    "\n",
    "df_cdom_bc.index = df_cdom_bc['Sample_idx']\n",
    "df_cdom_bc['Sample'] = df_cdom_bc.index\n",
    "df_cdom_bc.index = df_cdom_bc['Sample']\n",
    "\n",
    "df_iron_bc.index = df_iron_bc['Sample_idx']\n",
    "df_iron_bc['Sample'] = df_iron_bc.index\n",
    "df_iron_bc.index = df_iron_bc['Sample']\n",
    "\n",
    "df_fe_cdom = df_fe_cdom.drop('Sample_idx', axis = 1)\n",
    "df_iron_bc = df_iron_bc.drop('Sample_idx', axis = 1)\n",
    "df_cdom_bc = df_cdom_bc.drop('Sample_idx', axis = 1)\n",
    "\n",
    "\n",
    "# Step 2: Conducting a linear regression\n",
    "df_fe_cdom = df_fe_cdom.dropna(subset=['FeT_uM', 'acdom_350_bc'])\n",
    "#df_fe_cdom = df_fe_cdom.drop(df_fe_cdom[(df_fe_cdom['FeT_uM'] == 0) | (df_fe_cdom['acdom_350_bc'] >2)].index)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_fe_cdom['acdom_350_bc'], df_fe_cdom['FeT_uM'])\n",
    "\n",
    "# Step 3: Finding the ratio where NPOC_uM is equal to acdom_350_bc\n",
    "# slope * x + intercept = x  =>  x * (slope - 1) = -intercept  =>  x = -intercept / (slope - 1)\n",
    "x_equal = slope\n",
    "x_err = std_err\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Step 1: Plotting the scatter plot\n",
    "plt.scatter(df_fe_cdom['acdom_350_bc'], df_fe_cdom['FeT_uM'], color='blue', label='Data points')\n",
    "# Step 4: Plotting the regression line\n",
    "x_vals = df_fe_cdom['acdom_350_bc']\n",
    "y_vals = slope * x_vals + intercept\n",
    "plt.plot(x_vals, y_vals, color='red', label=f'Regression Line (y={slope:.2f}x + {intercept:.2f})')\n",
    "\n",
    "plt.xlim(0,2)\n",
    "plt.ylim(0,400)\n",
    "\n",
    "# Step 5: Annotating the plot with the calculated ratio and r-value\n",
    "plt.annotate(f'slope (NPOC:acdom) = {x_equal:.2f}', xy=(0.07, 0.9), xycoords='axes fraction')\n",
    "plt.annotate(f'R-value = {r_value:.2f}', xy=(0.1, 0.85), xycoords='axes fraction')\n",
    "\n",
    "plt.ylabel('NPOC_uM')\n",
    "plt.xlabel('acdom_350_bc')\n",
    "plt.legend()\n",
    "plt.title('Scatter plot with Linear Regression')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "x_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cffda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get BC data sets \n",
    "df_cdom_bc = df_cdom[df_cdom['Type'] == 'LANDSYR']\n",
    "df_iron_bc = df_iron[df_iron['Type'] == 'BC']\n",
    "df_doc_bc = df_doc[df_doc['Type'] == 'BC']\n",
    "\n",
    "#get PW data sets \n",
    "df_cdom_pw = df_cdom[df_cdom['Type'] == 'PW']\n",
    "df_iron_pw = df_iron[df_iron['Type'] == 'PW']\n",
    "df_doc_pw = df_doc[df_doc['Type'] == 'PW']\n",
    "\n",
    "#get WC data sets \n",
    "df_cdom_wc = df_cdom[df_cdom['Type'] == 'NISK']\n",
    "df_iron_wc = df_iron[df_iron['Type'] == 'WC']\n",
    "df_doc_wc = df_doc[df_doc['Type'] == 'WC']\n",
    "\n",
    "#get RHZ data \n",
    "df_cdom_rz = df_cdom[df_cdom['Type'] == 'RHZ']\n",
    "df_iron_rz = df_iron[df_iron['Type'].isin(['RZ', 'GBRZ'])]\n",
    "df_doc_rz = df_doc[df_doc['Type'] == 'RZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hights = pd.read_csv('../Dissertation_projects/Data/Hights.csv', sep=',')\n",
    "\n",
    "df_hights['code'] = df_hights['Stn'] + '_' + df_hights['Camp']\n",
    "#df_hights.drop(\"Stn\", axis=1, inplace=True)\n",
    "#df_hights.drop(\"Camp\", axis=1, inplace=True)\n",
    "df_hights.index = df_hights['code']\n",
    "df_hights.drop(\"code\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b034193",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#DOC slopes \n",
    "df_doc_bc_plot = df_doc_bc[(df_doc_bc['NPOC_uM'] != 0)]\n",
    "df_doc_bc_plot = df_doc_bc_plot.dropna(subset=[\"NPOC_uM\"])\n",
    "codes = df_doc_bc_plot['code'].unique()\n",
    "df_doc_bc_plot = df_doc_bc_plot[df_doc_bc_plot['code'] != 'St.13_GOM22SP']\n",
    "\n",
    "#make plot\n",
    "fig, axs = plt.subplots(nrows=10, ncols=3, figsize=(14, 20)) \n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_doc_bc_plot.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    \n",
    "    x = group['Time']\n",
    "    y = group['NPOC_uM']\n",
    "    \n",
    "    xx4 = group.loc[group['Time'] < 4, 'Time'].ravel()\n",
    "    yy4 = group.loc[group['Time'] < 4, 'NPOC_uM'].ravel()\n",
    "    \n",
    "    xx6 = group.loc[group['Time'] < 6, 'Time'].ravel()\n",
    "    yy6 = group.loc[group['Time'] < 6, 'NPOC_uM'].ravel()\n",
    "    \n",
    "    xx8 = group.loc[group['Time'] < 8, 'Time'].ravel()\n",
    "    yy8 = group.loc[group['Time'] < 8, 'NPOC_uM'].ravel()\n",
    "    \n",
    "    xx10 = group.loc[group['Time'] < 10, 'Time'].ravel()\n",
    "    yy10 = group.loc[group['Time'] < 10, 'NPOC_uM'].ravel()\n",
    "    \n",
    "    # Plot the data for this subgroup on its corresponding subplot\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    sc = ax.scatter(x, y, c=\"black\")\n",
    "    \n",
    "    # Add subplot labels\n",
    "    ax.set_title(code)\n",
    "    ax.set_xlabel('Time in Hours')\n",
    "    ax.set_ylabel('DOC uM')\n",
    "    ax.set_xlim(0,df_doc_bc['Time'].max())\n",
    "    ax.set_ylim(df_doc_bc['NPOC_uM'].min(),df_doc_bc['NPOC_uM'].max())\n",
    "    \n",
    "    # Calculate the slope of the regression line\n",
    "    slope4, intercept4, r_value4, p_value4, std_err4 = stats.linregress(xx4, yy4)\n",
    "    slope6, intercept6, r_value6, p_value6, std_err6 = stats.linregress(xx6, yy6)\n",
    "    slope8, intercept8, r_value8, p_value8, std_err6 = stats.linregress(xx8, yy8)\n",
    "    slope1, intercept1, r_value1, p_value1, std_err1 = stats.linregress(xx10, yy10)\n",
    "\n",
    "    # Add the regression line to the plot\n",
    "    ax.plot(x, intercept4 + slope4 * x, c='r')\n",
    "    ax.plot(x, intercept6 + slope6 * x, c='g')\n",
    "    ax.plot(x, intercept8 + slope8 * x, c='b')\n",
    "    ax.plot(x, intercept1 + slope1 * x, c='y')\n",
    "\n",
    "    \n",
    "    # Add the equation of the regression line to the plot\n",
    "    #equation = f'y = {slope:.2f}x + {intercept:.2f}'\n",
    "    #ax.text(1, 390, equation)\n",
    "    \n",
    "    # Add the r-squared value to the plot\n",
    "    rsquared4 = f'R² = {r_value4**2:.2f}'\n",
    "    rsquared6 = f'R² = {r_value6**2:.2f}'\n",
    "    rsquared8 = f'R² = {r_value8**2:.2f}'\n",
    "    rsquared1 = f'R² = {r_value1**2:.2f}'\n",
    "\n",
    "    ax.text(1, 400, rsquared4, c='r')\n",
    "    ax.text(1, 300, rsquared6, c='g')\n",
    "    ax.text(1, 200, rsquared8, c='b')\n",
    "    ax.text(1, 100, rsquared1, c='y')\n",
    "    \n",
    "    # Add the slope value to the plot\n",
    "    #sloped = f'Slope = {slope:.3f}'\n",
    "    #ax.text(1, 270, sloped, fontweight='bold')\n",
    "\n",
    "# Add overall figure labels and color bar\n",
    "fig.suptitle(r'DOC Slopes and intercepts' '\\n')\n",
    "plt.tight_layout()\n",
    "fig.set_facecolor('w')\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/DOC_flux.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOC slopes Calculate \n",
    "Frames = []\n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_doc_bc_plot.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    \n",
    "    xx4 = group.loc[group['Time'] < 4, 'Time'].ravel()\n",
    "    yy4 = group.loc[group['Time'] < 4, 'NPOC_uM'].ravel()\n",
    "    \n",
    "    xx6 = group.loc[group['Time'] < 6, 'Time'].ravel()\n",
    "    yy6 = group.loc[group['Time'] < 6, 'NPOC_uM'].ravel()\n",
    "    \n",
    "    xx8 = group.loc[group['Time'] < 8, 'Time'].ravel()\n",
    "    yy8 = group.loc[group['Time'] < 8, 'NPOC_uM'].ravel()\n",
    "    \n",
    "    xx10 = group.loc[group['Time'] < 10, 'Time'].ravel()\n",
    "    yy10 = group.loc[group['Time'] < 10, 'NPOC_uM'].ravel()    \n",
    "        \n",
    "    # Calculate the slope of the regression line\n",
    "    slope4, intercept4, r_value4, p_value4, std_err4 = stats.linregress(xx4, yy4)\n",
    "    slope6, intercept6, r_value6, p_value6, std_err6 = stats.linregress(xx6, yy6)\n",
    "    slope8, intercept8, r_value8, p_value8, std_err8 = stats.linregress(xx8, yy8)\n",
    "    slope1, intercept1, r_value1, p_value1, std_err1 = stats.linregress(xx10, yy10)\n",
    "    \n",
    "    r_squared_values = {\n",
    "        'r4': std_err4,\n",
    "        'r6': std_err6,\n",
    "        'r8': std_err8,\n",
    "        'r10':std_err1}\n",
    "\n",
    "    r_squared_values = {key: value for key, value in r_squared_values.items() if value != 0}\n",
    "    max_key = min(r_squared_values, key=r_squared_values.get)\n",
    "\n",
    "    if max_key == 'r4':\n",
    "        best_slope = slope4\n",
    "        best_r_squared = r_value4**2\n",
    "        best_std_err = std_err4\n",
    "        note_hours = \"4 hours\"\n",
    "    elif max_key == 'r6':\n",
    "        best_slope = slope6\n",
    "        best_r_squared = r_value6**2\n",
    "        best_std_err = std_err6\n",
    "        note_hours = \"6 hours\"\n",
    "    elif max_key == 'r8':\n",
    "        best_slope = slope8\n",
    "        best_r_squared = r_value8**2\n",
    "        best_std_err = std_err8 \n",
    "        note_hours = \"8 hours\"\n",
    "    else:\n",
    "        best_slope = slope1\n",
    "        best_r_squared = r_value1**2\n",
    "        best_std_err = std_err1\n",
    "        note_hours = \"10 hours\"\n",
    "    \n",
    "    # Add the slope value to the plot\n",
    "    slope = best_slope\n",
    "    rsquared = best_r_squared\n",
    "    std_err = best_std_err\n",
    "    \n",
    "    dic = {'code':[code],\n",
    "           'slope_doc':[slope],\n",
    "           'rsquared_doc':[rsquared], \n",
    "           'std_err_doc':[std_err],\n",
    "           'note_doc': [note_hours]}\n",
    "    \n",
    "    slopes = pd.DataFrame(dic)\n",
    "    slopes = slopes.set_index('code', drop=True)\n",
    "    \n",
    "    Frames.append(slopes)\n",
    "\n",
    "slopes_doc = pd.concat(Frames, axis=0, ignore_index=False)\n",
    "slopes_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nitrogen slopes\n",
    "fig, axs = plt.subplots(nrows=10, ncols=3, figsize=(16, 20)) \n",
    "\n",
    "df_tn_bc_plot = df_doc_bc[(df_doc_bc['TN_uM'] != 0)]\n",
    "df_tn_bc_plot = df_tn_bc_plot.dropna(subset=[\"TN_uM\"])\n",
    "codes = df_tn_bc_plot['code'].unique()\n",
    "df_tn_bc_plot = df_tn_bc_plot[df_tn_bc_plot['code'] != 'St.13_GOM22SP']\n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_tn_bc_plot.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    \n",
    "    x = group['Time']\n",
    "    y = group['TN_uM']\n",
    "    \n",
    "    xx4 = group.loc[group['Time'] < 4, 'Time'].ravel()\n",
    "    yy4 = group.loc[group['Time'] < 4, 'TN_uM'].ravel()\n",
    "    \n",
    "    xx6 = group.loc[group['Time'] < 6, 'Time'].ravel()\n",
    "    yy6 = group.loc[group['Time'] < 6, 'TN_uM'].ravel()\n",
    "    \n",
    "    xx8 = group.loc[group['Time'] < 8, 'Time'].ravel()\n",
    "    yy8 = group.loc[group['Time'] < 8, 'TN_uM'].ravel()\n",
    "    \n",
    "    xx10 = group.loc[group['Time'] < 10, 'Time'].ravel()\n",
    "    yy10 = group.loc[group['Time'] < 10, 'TN_uM'].ravel()\n",
    "    \n",
    "    # Plot the data for this subgroup on its corresponding subplot\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    sc = ax.scatter(x, y, c='green')\n",
    "    \n",
    "    # Add subplot labels\n",
    "    ax.set_title(code)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('TN uM')\n",
    "    ax.set_xlim(0,df_doc_bc['Time'].max())\n",
    "    ax.set_ylim(df_doc_bc['TN_uM'].min(),df_doc_bc['TN_uM'].max())\n",
    "    \n",
    "    # Calculate the slope of the regression line\n",
    "    slope4, intercept4, r_value4, p_value4, std_err4 = stats.linregress(xx4, yy4)\n",
    "    slope6, intercept6, r_value6, p_value6, std_err6 = stats.linregress(xx6, yy6)\n",
    "    slope8, intercept8, r_value8, p_value8, std_err6 = stats.linregress(xx8, yy8)\n",
    "    slope1, intercept1, r_value1, p_value1, std_err1 = stats.linregress(xx10, yy10)\n",
    "\n",
    "    # Add the regression line to the plot\n",
    "    ax.plot(x, intercept4 + slope4 * x, c='r')\n",
    "    ax.plot(x, intercept6 + slope6 * x, c='g')\n",
    "    ax.plot(x, intercept8 + slope8 * x, c='b')\n",
    "    ax.plot(x, intercept1 + slope1 * x, c='y')\n",
    "\n",
    "    \n",
    "    # Add the equation of the regression line to the plot\n",
    "    #equation = f'y = {slope:.2f}x + {intercept:.2f}'\n",
    "    #ax.text(1, 390, equation)\n",
    "    \n",
    "    # Add the r-squared value to the plot\n",
    "    rsquared4 = f'R² = {r_value4**2:.2f}'\n",
    "    rsquared6 = f'R² = {r_value6**2:.2f}'\n",
    "    rsquared8 = f'R² = {r_value8**2:.2f}'\n",
    "    rsquared1 = f'R² = {r_value1**2:.2f}'\n",
    "\n",
    "    ax.text(1, 35, rsquared4, c='r')\n",
    "    ax.text(1, 30, rsquared6, c='g')\n",
    "    ax.text(1, 25, rsquared8, c='b')\n",
    "    ax.text(1, 20, rsquared1, c='y')\n",
    "    \n",
    "    # Add the slope value to the plot\n",
    "    #sloped = f'Slope = {slope:.3f}'\n",
    "    #ax.text(1, 270, sloped, fontweight='bold')\n",
    "\n",
    "# Add overall figure labels and color bar\n",
    "fig.suptitle(r'TN Slopes and intercepts:'+' \\n')\n",
    "plt.tight_layout()\n",
    "fig.set_facecolor('w')\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/TN_flux.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TN slopes Calculate \n",
    "Frames = []\n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_tn_bc_plot.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    \n",
    "    xx4 = group.loc[group['Time'] < 4, 'Time'].ravel()\n",
    "    yy4 = group.loc[group['Time'] < 4, 'TN_uM'].ravel()\n",
    "    \n",
    "    xx6 = group.loc[group['Time'] < 6, 'Time'].ravel()\n",
    "    yy6 = group.loc[group['Time'] < 6, 'TN_uM'].ravel()\n",
    "    \n",
    "    xx8 = group.loc[group['Time'] < 8, 'Time'].ravel()\n",
    "    yy8 = group.loc[group['Time'] < 8, 'TN_uM'].ravel()\n",
    "    \n",
    "    xx10 = group.loc[group['Time'] < 10, 'Time'].ravel()\n",
    "    yy10 = group.loc[group['Time'] < 10, 'TN_uM'].ravel()    \n",
    "        \n",
    "    # Calculate the slope of the regression line\n",
    "    slope4, intercept4, r_value4, p_value4, std_err4 = stats.linregress(xx4, yy4)\n",
    "    slope6, intercept6, r_value6, p_value6, std_err6 = stats.linregress(xx6, yy6)\n",
    "    slope8, intercept8, r_value8, p_value8, std_err8 = stats.linregress(xx8, yy8)\n",
    "    slope1, intercept1, r_value1, p_value1, std_err1 = stats.linregress(xx10, yy10)\n",
    "    \n",
    "    r_squared_values = {\n",
    "        'r4': std_err4,\n",
    "        'r6': std_err6,\n",
    "        'r8': std_err8,\n",
    "        'r10':std_err1}\n",
    "\n",
    "    r_squared_values = {key: value for key, value in r_squared_values.items() if value != 0}\n",
    "    max_key = min(r_squared_values, key=r_squared_values.get)\n",
    "\n",
    "    if max_key == 'r4':\n",
    "        best_slope = slope4\n",
    "        best_r_squared = r_value4**2\n",
    "        best_std_err = std_err4\n",
    "        note_hours = \"4 hours\"\n",
    "    elif max_key == 'r6':\n",
    "        best_slope = slope6\n",
    "        best_r_squared = r_value6**2\n",
    "        best_std_err = std_err6\n",
    "        note_hours = \"6 hours\"\n",
    "    elif max_key == 'r8':\n",
    "        best_slope = slope8\n",
    "        best_r_squared = r_value8**2\n",
    "        best_std_err = std_err8 \n",
    "        note_hours = \"8 hours\"\n",
    "    else:\n",
    "        best_slope = slope1\n",
    "        best_r_squared = r_value1**2\n",
    "        best_std_err = std_err1\n",
    "        note_hours = \"10 hours\"\n",
    "    \n",
    "    # Add the slope value to the plot\n",
    "    slope = best_slope\n",
    "    rsquared = best_r_squared\n",
    "    std_err = best_std_err\n",
    "    \n",
    "    dic = {'code':[code],\n",
    "           'slope_tn':[slope],\n",
    "           'rsquared_tn':[rsquared], \n",
    "           'std_err_tn':[std_err],\n",
    "           'note_tn': [note_hours]}\n",
    "    \n",
    "    slopes = pd.DataFrame(dic)\n",
    "    slopes = slopes.set_index('code', drop=True)\n",
    "    \n",
    "    Frames.append(slopes)\n",
    "\n",
    "slopes_tn = pd.concat(Frames, axis=0, ignore_index=False)\n",
    "slopes_tn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55eca2",
   "metadata": {},
   "source": [
    "#CDOM slopes\n",
    "\n",
    "#df_cdom_bc_plot = df_cdom_bc[df_cdom_bc['code'] != 'St.13_GOM22SP']\n",
    "#df_cdom_bc_plot = df_cdom_bc_plot[df_cdom_bc_plot['code'] != 'St.14_GOM2021']\n",
    "#df_cdom_bc_plot = df_cdom_bc_plot.dropna(subset=['acdom_412_bc'])\n",
    "codes = df_cdom_bc_plot['code'].unique()\n",
    "\n",
    "fig, axs = plt.subplots(nrows=13, ncols=3, figsize=(16, 25)) \n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_cdom_bc_plot.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    \n",
    "    x = group['BC_time']\n",
    "    y = group['acdom_412_bc']\n",
    "    \n",
    "    xx4 = group.loc[group['BC_time'] < 4, 'BC_time'].ravel()\n",
    "    yy4 = group.loc[group['BC_time'] < 4, 'acdom_412_bc'].ravel()\n",
    "    \n",
    "    xx6 = group.loc[group['BC_time'] < 6, 'BC_time'].ravel()\n",
    "    yy6 = group.loc[group['BC_time'] < 6, 'acdom_412_bc'].ravel()\n",
    "    \n",
    "    xx8 = group.loc[group['BC_time'] < 8, 'BC_time'].ravel()\n",
    "    yy8 = group.loc[group['BC_time'] < 8, 'acdom_412_bc'].ravel()\n",
    "    \n",
    "    xx10 = group.loc[group['BC_time'] < 10, 'BC_time'].ravel()\n",
    "    yy10 = group.loc[group['BC_time'] < 10, 'acdom_412_bc'].ravel()\n",
    "    \n",
    "    # Plot the data for this subgroup on its corresponding subplot\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    sc = ax.scatter(x, y, c='y')\n",
    "    \n",
    "    # Add subplot labels\n",
    "    ax.set_title(code)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('aCDOM 412')\n",
    "    ax.set_xlim(0,df_doc_bc['Time'].max())\n",
    "    ax.set_ylim(-1,2)\n",
    "    \n",
    "    # Calculate the slope of the regression line\n",
    "    slope4, intercept4, r_value4, p_value4, std_err4 = stats.linregress(xx4, yy4)\n",
    "    slope6, intercept6, r_value6, p_value6, std_err6 = stats.linregress(xx6, yy6)\n",
    "    slope8, intercept8, r_value8, p_value8, std_err6 = stats.linregress(xx8, yy8)\n",
    "    slope1, intercept1, r_value1, p_value1, std_err1 = stats.linregress(xx10, yy10)\n",
    "\n",
    "    # Add the regression line to the plot\n",
    "    ax.plot(x, intercept4 + slope4 * x, c='r')\n",
    "    ax.plot(x, intercept6 + slope6 * x, c='g')\n",
    "    ax.plot(x, intercept8 + slope8 * x, c='b')\n",
    "    ax.plot(x, intercept1 + slope1 * x, c='y')\n",
    "    \n",
    "    # Add the equation of the regression line to the plot\n",
    "    #equation = f'y = {slope:.2f}x + {intercept:.2f}'\n",
    "    #ax.text(1, 390, equation)\n",
    "    \n",
    "    # Add the r-squared value to the plot\n",
    "    rsquared4 = f'R² = {r_value4**2:.2f}'\n",
    "    rsquared6 = f'R² = {r_value6**2:.2f}'\n",
    "    rsquared8 = f'R² = {r_value8**2:.2f}'\n",
    "    rsquared1 = f'R² = {r_value1**2:.2f}'\n",
    "\n",
    "    ax.text(1, 2.2, rsquared4, c='r')\n",
    "    ax.text(1, 1.8, rsquared6, c='g')\n",
    "    ax.text(1, 1.4, rsquared8, c='b')\n",
    "    ax.text(1, 1, rsquared1, c='y')\n",
    "\n",
    "# Add overall figure labels and color bar\n",
    "fig.suptitle(r'$a_{\\mathrm{CDOM}}$ (m$^{-1}$) 412 nm'+'\\n')\n",
    "plt.tight_layout()\n",
    "fig.set_facecolor('w')\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/CDOM412_flux.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9b336",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#CDOM slopes\n",
    "df_cdom_bc_plot = df_cdom_bc[df_cdom_bc['code'] != 'St.13_GOM22SP']\n",
    "df_cdom_bc_plot = df_cdom_bc_plot[df_cdom_bc_plot['code'] != 'St.14_GOM2021']\n",
    "df_cdom_bc_plot = df_cdom_bc_plot.dropna(subset=['acdom_350_bc'])\n",
    "codes = df_cdom_bc_plot['code'].unique()\n",
    "\n",
    "fig, axs = plt.subplots(nrows=13, ncols=3, figsize=(16, 25)) \n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_cdom_bc_plot.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    \n",
    "    x = group['BC_time']\n",
    "    y = group['acdom_350_bc']\n",
    "    \n",
    "    xx4 = group.loc[group['BC_time'] < 4, 'BC_time'].ravel()\n",
    "    yy4 = group.loc[group['BC_time'] < 4, 'acdom_350_bc'].ravel()\n",
    "    \n",
    "    xx6 = group.loc[group['BC_time'] < 6, 'BC_time'].ravel()\n",
    "    yy6 = group.loc[group['BC_time'] < 6, 'acdom_350_bc'].ravel()\n",
    "    \n",
    "    xx8 = group.loc[group['BC_time'] < 8, 'BC_time'].ravel()\n",
    "    yy8 = group.loc[group['BC_time'] < 8, 'acdom_350_bc'].ravel()\n",
    "    \n",
    "    xx10 = group.loc[group['BC_time'] < 10, 'BC_time'].ravel()\n",
    "    yy10 = group.loc[group['BC_time'] < 10, 'acdom_350_bc'].ravel()\n",
    "    \n",
    "    # Plot the data for this subgroup on its corresponding subplot\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    sc = ax.scatter(x, y, c='y')\n",
    "    \n",
    "    # Add subplot labels\n",
    "    ax.set_title(code)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('aCDOM 350')\n",
    "    ax.set_xlim(0,df_doc_bc['Time'].max())\n",
    "    ax.set_ylim(-1,2)\n",
    "    \n",
    "    # Calculate the slope of the regression line\n",
    "    slope4, intercept4, r_value4, p_value4, std_err4 = stats.linregress(xx4, yy4)\n",
    "    slope6, intercept6, r_value6, p_value6, std_err6 = stats.linregress(xx6, yy6)\n",
    "    slope8, intercept8, r_value8, p_value8, std_err6 = stats.linregress(xx8, yy8)\n",
    "    slope1, intercept1, r_value1, p_value1, std_err1 = stats.linregress(xx10, yy10)\n",
    "\n",
    "    # Add the regression line to the plot\n",
    "    ax.plot(x, intercept4 + slope4 * x, c='r')\n",
    "    ax.plot(x, intercept6 + slope6 * x, c='g')\n",
    "    ax.plot(x, intercept8 + slope8 * x, c='b')\n",
    "    ax.plot(x, intercept1 + slope1 * x, c='y')\n",
    "    \n",
    "    # Add the equation of the regression line to the plot\n",
    "    #equation = f'y = {slope:.2f}x + {intercept:.2f}'\n",
    "    #ax.text(1, 390, equation)\n",
    "    \n",
    "    # Add the r-squared value to the plot\n",
    "    rsquared4 = f'R² = {r_value4**2:.2f}'\n",
    "    rsquared6 = f'R² = {r_value6**2:.2f}'\n",
    "    rsquared8 = f'R² = {r_value8**2:.2f}'\n",
    "    rsquared1 = f'R² = {r_value1**2:.2f}'\n",
    "\n",
    "    ax.text(1, 2.2, rsquared4, c='r')\n",
    "    ax.text(1, 1.8, rsquared6, c='g')\n",
    "    ax.text(1, 1.4, rsquared8, c='b')\n",
    "    ax.text(1, 1, rsquared1, c='y')\n",
    "\n",
    "# Add overall figure labels and color bar\n",
    "fig.suptitle(r'$a_{\\mathrm{CDOM}}$ (m$^{-1}$) 350 nm'+'\\n')\n",
    "plt.tight_layout()\n",
    "fig.set_facecolor('w')\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/CDOM350_flux.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd0290",
   "metadata": {},
   "source": [
    "#cdom slopes Calculate \n",
    "Frames = []\n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_cdom_bc_plot.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    \n",
    "    xx4 = group.loc[group['BC_time'] < 4, 'BC_time'].ravel()\n",
    "    yy4 = group.loc[group['BC_time'] < 4, 'acdom_412_bc'].ravel()\n",
    "    \n",
    "    xx6 = group.loc[group['BC_time'] < 6, 'BC_time'].ravel()\n",
    "    yy6 = group.loc[group['BC_time'] < 6, 'acdom_412_bc'].ravel()\n",
    "    \n",
    "    xx8 = group.loc[group['BC_time'] < 8, 'BC_time'].ravel()\n",
    "    yy8 = group.loc[group['BC_time'] < 8, 'acdom_412_bc'].ravel()\n",
    "    \n",
    "    xx10 = group.loc[group['BC_time'] < 10, 'BC_time'].ravel()\n",
    "    yy10 = group.loc[group['BC_time'] < 10, 'acdom_412_bc'].ravel()    \n",
    "        \n",
    "    # Calculate the slope of the regression line\n",
    "    slope4, intercept4, r_value4, p_value4, std_err4 = stats.linregress(xx4, yy4)\n",
    "    slope6, intercept6, r_value6, p_value6, std_err6 = stats.linregress(xx6, yy6)\n",
    "    slope8, intercept8, r_value8, p_value8, std_err8 = stats.linregress(xx8, yy8)\n",
    "    slope1, intercept1, r_value1, p_value1, std_err1 = stats.linregress(xx10, yy10)\n",
    "    \n",
    "    r_squared_values = {\n",
    "        'r4': std_err4,\n",
    "        'r6': std_err6,\n",
    "        'r8': std_err8,\n",
    "        'r10':std_err1}\n",
    "\n",
    "    r_squared_values = {key: value for key, value in r_squared_values.items() if value != 0}\n",
    "    max_key = min(r_squared_values, key=r_squared_values.get)\n",
    "\n",
    "    if max_key == 'r4':\n",
    "        best_slope = slope4\n",
    "        best_r_squared = r_value4**2\n",
    "        best_std_err = std_err4\n",
    "        note_hours = \"4 hours\"\n",
    "    elif max_key == 'r6':\n",
    "        best_slope = slope6\n",
    "        best_r_squared = r_value6**2\n",
    "        best_std_err = std_err6\n",
    "        note_hours = \"6 hours\"\n",
    "    elif max_key == 'r8':\n",
    "        best_slope = slope8\n",
    "        best_r_squared = r_value8**2\n",
    "        best_std_err = std_err8 \n",
    "        note_hours = \"8 hours\"\n",
    "    else:\n",
    "        best_slope = slope1\n",
    "        best_r_squared = r_value1**2\n",
    "        best_std_err = std_err1\n",
    "        note_hours = \"10 hours\"\n",
    "    \n",
    "    # Add the slope value to the plot\n",
    "    slope = best_slope\n",
    "    rsquared = best_r_squared\n",
    "    std_err = best_std_err\n",
    "    \n",
    "    dic = {'code':[code],\n",
    "           'slope_a412':[slope],\n",
    "           'rsquared_a412':[rsquared], \n",
    "           'std_err_a412':[std_err],\n",
    "           'note_a412': [note_hours]}\n",
    "    \n",
    "    slopes = pd.DataFrame(dic)\n",
    "    slopes = slopes.set_index('code', drop=True)\n",
    "    \n",
    "    Frames.append(slopes)\n",
    "\n",
    "slopes_a412 = pd.concat(Frames, axis=0, ignore_index=False)\n",
    "slopes_a412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cdom slopes Calculate \n",
    "Frames = []\n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_cdom_bc_plot.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    \n",
    "    xx4 = group.loc[group['BC_time'] < 4, 'BC_time'].ravel()\n",
    "    yy4 = group.loc[group['BC_time'] < 4, 'acdom_350_bc']*x_equal.ravel()\n",
    "    \n",
    "    xx6 = group.loc[group['BC_time'] < 6, 'BC_time'].ravel()\n",
    "    yy6 = group.loc[group['BC_time'] < 6, 'acdom_350_bc']*x_equal.ravel()\n",
    "    \n",
    "    xx8 = group.loc[group['BC_time'] < 8, 'BC_time'].ravel()\n",
    "    yy8 = group.loc[group['BC_time'] < 8, 'acdom_350_bc']*x_equal.ravel()\n",
    "    \n",
    "    xx10 = group.loc[group['BC_time'] < 10, 'BC_time'].ravel()\n",
    "    yy10 = group.loc[group['BC_time'] < 10, 'acdom_350_bc']*x_equal.ravel()    \n",
    "        \n",
    "    # Calculate the slope of the regression line\n",
    "    slope4, intercept4, r_value4, p_value4, std_err4 = stats.linregress(xx4, yy4)\n",
    "    slope6, intercept6, r_value6, p_value6, std_err6 = stats.linregress(xx6, yy6)\n",
    "    slope8, intercept8, r_value8, p_value8, std_err8 = stats.linregress(xx8, yy8)\n",
    "    slope1, intercept1, r_value1, p_value1, std_err1 = stats.linregress(xx10, yy10)\n",
    "    \n",
    "    r_squared_values = {\n",
    "        'r4': std_err4,\n",
    "        'r6': std_err6,\n",
    "        'r8': std_err8,\n",
    "        'r10':std_err1}\n",
    "\n",
    "    r_squared_values = {key: value for key, value in r_squared_values.items() if value != 0}\n",
    "    max_key = min(r_squared_values, key=r_squared_values.get)\n",
    "\n",
    "    if max_key == 'r4':\n",
    "        best_slope = slope4\n",
    "        best_r_squared = r_value4**2\n",
    "        best_std_err = std_err4\n",
    "        note_hours = \"4 hours\"\n",
    "    elif max_key == 'r6':\n",
    "        best_slope = slope6\n",
    "        best_r_squared = r_value6**2\n",
    "        best_std_err = std_err6\n",
    "        note_hours = \"6 hours\"\n",
    "    elif max_key == 'r8':\n",
    "        best_slope = slope8\n",
    "        best_r_squared = r_value8**2\n",
    "        best_std_err = std_err8 \n",
    "        note_hours = \"8 hours\"\n",
    "    else:\n",
    "        best_slope = slope1\n",
    "        best_r_squared = r_value1**2\n",
    "        best_std_err = std_err1\n",
    "        note_hours = \"10 hours\"\n",
    "    \n",
    "    # Add the slope value to the plot\n",
    "    slope = best_slope\n",
    "    rsquared = best_r_squared\n",
    "    std_err = best_std_err\n",
    "    \n",
    "    dic = {'code':[code],\n",
    "           'slope_a350':[slope],\n",
    "           'rsquared_a350':[rsquared], \n",
    "           'std_err_a350':[std_err],\n",
    "           'note_a350': [note_hours]}\n",
    "    \n",
    "    slopes = pd.DataFrame(dic)\n",
    "    slopes = slopes.set_index('code', drop=True)\n",
    "    \n",
    "    Frames.append(slopes)\n",
    "\n",
    "slopes_a350 = pd.concat(Frames, axis=0, ignore_index=False)\n",
    "slopes_a350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c8aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean out the Iron data for the slopes \n",
    "df_iron_bc_fe2_cl = df_iron_bc.drop(df_iron_bc[(df_iron_bc['Fe2_uM'] == 0) | (df_iron_bc['Fe2_uM'].isna())].index)\n",
    "\n",
    "#clean out the Iron data for the slopes \n",
    "df_iron_bc_fe3_cl = df_iron_bc.drop(df_iron_bc[(df_iron_bc['Fe3_uM'] == 0) | (df_iron_bc['Fe3_uM'].isna())].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e88665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iron 2 slopes \n",
    "\n",
    "fig, axs = plt.subplots(nrows=12, ncols=3, figsize=(16, 25)) \n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_iron_bc_fe2_cl.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    x = group['Fe2_Time']\n",
    "    y = group['Fe2_uM']\n",
    "    \n",
    "    xx = group.loc[group['Fe2_Time'] <6 , 'Fe2_Time'].ravel()\n",
    "    yy = group.loc[group['Fe2_Time'] <6, 'Fe2_uM'].ravel()\n",
    "    \n",
    "    # Plot the data for this subgroup on its corresponding subplot\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    sc = ax.scatter(x, y, c='b')\n",
    "    \n",
    "    # Add subplot labels\n",
    "    ax.set_title(code)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Iron(II) uM')\n",
    "    ax.set_xlim(0,df_iron_bc_fe2_cl['Fe2_Time'].max())\n",
    "    ax.set_ylim(0,max(y))\n",
    "    \n",
    "    if len(xx) > 0 and len(yy) > 0:\n",
    "        # Calculate the slope of the regression line\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(xx, yy)\n",
    "        \n",
    "        # Add the regression line to the plot\n",
    "        ax.plot(x, intercept + slope * x, c='r')\n",
    "    \n",
    "        # Add the equation of the regression line to the plot\n",
    "        equation = f'y = {slope:.2f}x + {intercept:.2f}'\n",
    "        ax.text(1, max(y)*.85, equation)\n",
    "    \n",
    "        # Add the r-squared value to the plot\n",
    "        rsquared = f'R² = {r_value**2:.2f}'\n",
    "        ax.text(1, max(y)*.73, rsquared)\n",
    "    \n",
    "        # Add the slope value to the plot\n",
    "        sloped = f'Slope = {slope:.3f}'\n",
    "        ax.text(1, max(y)*.08, sloped, fontweight='bold')\n",
    "\n",
    "# Add overall figure labels and color bar\n",
    "fig.suptitle(r'Iorn (II) Slopes and intercepts' '\\n')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf283217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fe2 slopes Calculate \n",
    "Frames = []\n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_iron_bc_fe2_cl.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    \n",
    "    x = group.loc[group['Fe2_Time'] <6 , 'Fe2_Time'].ravel()\n",
    "    y = group.loc[group['Fe2_Time'] <6, 'Fe2_uM'].ravel()\n",
    "\n",
    "    if len(x) > 0 and len(y) > 0:\n",
    "        # Calculate the slope of the regression line\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "        # Add the r-squared value to the plot\n",
    "        rsquared = r_value**2\n",
    "    \n",
    "        # Add the slope value to the plot\n",
    "        slope = slope\n",
    "    \n",
    "        dic = {'code':[code],\n",
    "               'slope_fe2':[slope],\n",
    "               'rsquared_fe2':[rsquared]}\n",
    "    \n",
    "        slopes = pd.DataFrame(dic)\n",
    "        slopes = slopes.set_index('code', drop=True)\n",
    "    \n",
    "    Frames.append(slopes)\n",
    "\n",
    "slopes_fe2 = pd.concat(Frames, axis=0, ignore_index=False)\n",
    "slopes_fe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8584292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iron 3 slopes \n",
    "\n",
    "fig, axs = plt.subplots(nrows=9, ncols=3, figsize=(16, 20)) \n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_iron_bc_fe3_cl.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    x = group['FeT_Time'].ravel()\n",
    "    y = group['Fe3_uM'].ravel()\n",
    "    \n",
    "    xx = group.loc[group['FeT_Time'] <6 , 'FeT_Time'].ravel()\n",
    "    yy = group.loc[group['FeT_Time'] <6, 'Fe3_uM'].ravel()\n",
    "    \n",
    "    # Plot the data for this subgroup on its corresponding subplot\n",
    "    ax = axs[i // 3, i % 3]\n",
    "    sc = ax.scatter(x, y, c='r')\n",
    "    \n",
    "    # Add subplot labels\n",
    "    ax.set_title(code)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Iron(III) uM')\n",
    "    ax.set_xlim(0,df_iron_bc_fe3_cl['FeT_Time'].max())\n",
    "    ax.set_ylim(0,max(y))\n",
    "    \n",
    "    if len(xx) > 0 and len(yy) > 0:\n",
    "        # Calculate the slope of the regression line\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(xx, yy)\n",
    "\n",
    "    # Add the regression line to the plot\n",
    "        ax.plot(x, intercept + slope * x, c='r')\n",
    "    \n",
    "    # Add the equation of the regression line to the plot\n",
    "        equation = f'y = {slope:.2f}x + {intercept:.2f}'\n",
    "        ax.text(1, max(y)*.85, equation)\n",
    "    \n",
    "    # Add the r-squared value to the plot\n",
    "        rsquared = f'R² = {r_value**2:.2f}'\n",
    "        ax.text(1, max(y)*.73, rsquared)\n",
    "    \n",
    "    # Add the slope value to the plot\n",
    "        sloped = f'Slope = {slope:.3f}'\n",
    "        ax.text(1, max(y)*.08, sloped, fontweight='bold')\n",
    "\n",
    "# Add overall figure labels and color bar\n",
    "fig.suptitle(r'Iorn (III) Slopes and intercepts' '\\n')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc33fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fe3 slopes Calculate \n",
    "Frames = []\n",
    "\n",
    "# Group the data by 'code' and iterate over each subgroup\n",
    "for i, (code, group) in enumerate(df_iron_bc_fe3_cl.groupby('code')):\n",
    "    # Extract x, y, and c data from the group\n",
    "    \n",
    "    x = group.loc[group['FeT_Time'] <6 , 'FeT_Time'].ravel()\n",
    "    y = group.loc[group['FeT_Time'] <6, 'Fe3_uM'].ravel()    \n",
    "    \n",
    "    \n",
    "    if len(x) > 0 and len(y) > 0:\n",
    "        # Calculate the slope of the regression line\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    # Add the r-squared value to the plot\n",
    "        rsquared = r_value**2\n",
    "    \n",
    "    # Add the slope value to the plot\n",
    "        slope = slope\n",
    "    \n",
    "        dic = {'code':[code],\n",
    "               'slope_fe3':[slope],\n",
    "               'rsquared_fe3':[rsquared]}\n",
    "        \n",
    "        slopes = pd.DataFrame(dic)\n",
    "        slopes = slopes.set_index('code', drop=True)\n",
    "    \n",
    "    Frames.append(slopes)\n",
    "\n",
    "slopes_fe3 = pd.concat(Frames, axis=0, ignore_index=False)\n",
    "slopes_fe3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make location data \n",
    "df_lat_lon = df_meta.groupby('code').agg({'Lat': 'mean', 'Lon': 'mean'}).reset_index().set_index('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2685f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [df_hights, df_lat_lon, slopes_a350, slopes_doc, slopes_tn, slopes_fe2, slopes_fe3]\n",
    "for df in dataframes:\n",
    "    if not df.index.is_unique:\n",
    "        print(\"Duplicate indices found in dataframe:\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat it all \n",
    "df_flux = pd.concat([df_hights, df_lat_lon, slopes_a350, slopes_doc, slopes_tn, slopes_fe2, slopes_fe3], axis=1, join='outer')\n",
    "\n",
    "#calcute flux \n",
    "#df_flux[\"flux_aCDOM412\"] = df_flux[\"slope_a412\"] * (df_flux[\"Hight_m\"]*(np.pi*((30/100)**2))) / (np.pi*((30/100)**2)) * 24 \n",
    "df_flux[\"flux_aCDOM350\"] = df_flux[\"slope_a350\"] * (df_flux[\"Hight_m\"]*(np.pi*((30/100)**2))) / (np.pi*((30/100)**2)) * 24 \n",
    "df_flux[\"flux_doc\"] = df_flux[\"slope_doc\"] * (((df_flux[\"Hight_m\"]*(np.pi*((30/100)**2)))*1000) / (np.pi*((30/100)**2))) * 24 /1000\n",
    "\n",
    "df_flux[\"erros_aCDOM350\"] = np.sqrt( ((df_flux[\"std_err_a350\"] / df_flux[\"slope_a350\"])**2) + (((df_flux[\"Hight_error\"] / df_flux[\"Hight_m\"])**2)/1000))  \n",
    "df_flux[\"erros_doc\"] = np.sqrt( (df_flux[\"std_err_doc\"] / df_flux[\"slope_doc\"])**2 + (df_flux[\"Hight_error\"] / df_flux[\"Hight_m\"])**2 )\n",
    "\n",
    "#df_flux[\"flux_tn\"] = df_flux[\"slope_tn\"] * ((df_flux[\"Hight_m\"]*(np.pi*((30/100)**2)))*1000) / (np.pi*((30/100)**2)) * 24 / 1000 \n",
    "#df_flux[\"flux_fe2\"] = df_flux[\"slope_fe2\"] * df_flux[\"Hight_m\"] *24\n",
    "#df_flux[\"flux_fe3\"] = df_flux[\"slope_fe3\"] * df_flux[\"Hight_m\"] *24\n",
    "\n",
    "df_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e20ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique categories and subcategories\n",
    "df = df_flux.dropna(subset=[\"flux_doc\"])\n",
    "\n",
    "categories = ['St.5B','St.4','St.MK','St.7','St.16','St.2','St.9','St.14','St.15','St.13','St.11','St.12']\n",
    "subcategories = ['GOM2021', 'GOM21FA', 'GOM22SP', 'GOM22SU']\n",
    "\n",
    "# Define custom colors\n",
    "color_map = {\n",
    "    'GOM2021': 'darkred',\n",
    "    'GOM21FA': 'blue',\n",
    "    'GOM22SP': 'green',\n",
    "    'GOM22SU': 'purple'\n",
    "}\n",
    "\n",
    "# Define custom labels (if they differ from subcategory names)\n",
    "label_map = {\n",
    "    'GOM2021': 'Summer 2021',\n",
    "    'GOM21FA': 'Fall 2021',\n",
    "    'GOM22SP': 'Spring 2022',\n",
    "    'GOM22SU': 'Summer 2022'\n",
    "}\n",
    "\n",
    "barWidth = 0.25\n",
    "\n",
    "# Create figure with custom size\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "# Adjust the height ratios for the subplots\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[5, 1], hspace=0)  # Set hspace to 0\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "\n",
    "# Adjusted r for spacing between groups\n",
    "r = np.arange(0, len(categories) * 1.5, 1.5)\n",
    "positions = [r + i*barWidth for i in range(len(subcategories))]\n",
    "\n",
    "# Adjusted code for broken axis and added spaces between the groups\n",
    "for pos, subcat in zip(positions, subcategories):\n",
    "    values = []\n",
    "    errors = []\n",
    "    for cat in categories:\n",
    "        value = df[(df['Stn'] == cat) & (df['Camp'] == subcat)]['flux_doc'].values\n",
    "        error = df[(df['Stn'] == cat) & (df['Camp'] == subcat)]['erros_doc'].values\n",
    "        values.append(value[0] if len(value) > 0 else 0)\n",
    "        errors.append(error[0] if len(error) > 0 else 0)\n",
    "    \n",
    "    ax1.bar(pos, [v if v > 0 else 0 for v in values], width=barWidth, color=color_map[subcat],\n",
    "            label=label_map[subcat], yerr=[e if e > 0 else 0 for e in errors])\n",
    "    ax2.bar(pos, [v if v < 0 else 0 for v in values], width=barWidth, color=color_map[subcat],\n",
    "            label=label_map[subcat], yerr=[e if e > 0 else 0 for e in errors])\n",
    "    \n",
    "# Setting the limit for the break\n",
    "ax1.set_ylim(0, 120)  \n",
    "ax2.set_ylim(-120, 0)\n",
    "\n",
    "# Removing spines and ticks for the broken axis effect\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop='off')\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels\n",
    "ax2.set_xlabel('Stations: shallow to deep')\n",
    "ax1.set_ylabel(r'Flux of DOC (mmol m$^{-2}$ day$^{-1}$)')\n",
    "ax1.set_title('DOC flux: Benthic Chamber')\n",
    "ax2.set_xticks(r + 1.5*barWidth)  # Adjust for the spaces between groups\n",
    "ax2.set_xticklabels(categories)\n",
    "\n",
    "# Add black horizontal line at y=0\n",
    "ax1.axhline(0, color=\"black\", linewidth=0.5)\n",
    "ax2.axhline(0, color=\"black\", linewidth=0.5)\n",
    "\n",
    "handles, _ = plt.gca().get_legend_handles_labels()\n",
    "labels = [label_map[subcat] for subcat in subcategories]\n",
    "ax1.legend(handles[:len(subcategories)], labels)\n",
    "\n",
    "fig.set_facecolor('w')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/DOC_flux_barplot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique categories and subcategories\n",
    "df = df_flux.dropna(subset=[\"flux_doc\"])\n",
    "\n",
    "categories = ['St.5B','St.4','St.MK','St.7','St.16','St.2','St.9','St.14','St.15','St.13','St.11','St.12']\n",
    "subcategories = ['GOM2021', 'GOM21FA', 'GOM22SP', 'GOM22SU']\n",
    "\n",
    "# Define custom colors\n",
    "color_map = {\n",
    "    'GOM2021': 'darkred',\n",
    "    'GOM21FA': 'blue',\n",
    "    'GOM22SP': 'green',\n",
    "    'GOM22SU': 'purple'\n",
    "}\n",
    "\n",
    "# Define custom labels (if they differ from subcategory names)\n",
    "label_map = {\n",
    "    'GOM2021': 'Summer 2021',\n",
    "    'GOM21FA': 'Fall 2021',\n",
    "    'GOM22SP': 'Spring 2022',\n",
    "    'GOM22SU': 'Summer 2022'\n",
    "}\n",
    "\n",
    "barWidth = 0.25\n",
    "\n",
    "# Create figure with custom size\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "# Adjust the height ratios for the subplots\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[5, 1], hspace=0)  # Set hspace to 0\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "\n",
    "# Adjusted r for spacing between groups\n",
    "r = np.arange(0, len(categories) * 1.5, 1.5)\n",
    "positions = [r + i*barWidth for i in range(len(subcategories))]\n",
    "\n",
    "# Adjusted code for broken axis and added spaces between the groups\n",
    "for pos, subcat in zip(positions, subcategories):\n",
    "    values = []\n",
    "    errors = []\n",
    "    for cat in categories:\n",
    "        value = df[(df['Stn'] == cat) & (df['Camp'] == subcat)]['flux_doc'].values\n",
    "        error = df[(df['Stn'] == cat) & (df['Camp'] == subcat)]['erros_doc'].values\n",
    "        values.append(value[0] if len(value) > 0 else 0)\n",
    "        errors.append(error[0] if len(error) > 0 else 0)\n",
    "    \n",
    "    ax1.bar(pos, [v if v > 0 else 0 for v in values], width=barWidth, color=color_map[subcat],\n",
    "            label=label_map[subcat])#, yerr=[e if e > 0 else 0 for e in errors])\n",
    "    ax2.bar(pos, [v if v < 0 else 0 for v in values], width=barWidth, color=color_map[subcat],\n",
    "            label=label_map[subcat])#, yerr=[e if e > 0 else 0 for e in errors])\n",
    "    \n",
    "# Setting the limit for the break\n",
    "ax1.set_ylim(0, 95)  \n",
    "ax2.set_ylim(-95, 0)\n",
    "\n",
    "# Removing spines and ticks for the broken axis effect\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop='off')\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels\n",
    "ax2.set_xlabel('Stations: shallow to deep')\n",
    "ax1.set_ylabel(r'Flux of DOC (mmol m$^{-2}$ day$^{-1}$)')\n",
    "ax1.set_title('DOC flux: Benthic Chamber')\n",
    "ax2.set_xticks(r + 1.5*barWidth)  # Adjust for the spaces between groups\n",
    "ax2.set_xticklabels(categories)\n",
    "\n",
    "# Add black horizontal line at y=0\n",
    "ax1.axhline(0, color=\"black\", linewidth=0.5)\n",
    "ax2.axhline(0, color=\"black\", linewidth=0.5)\n",
    "\n",
    "handles, _ = plt.gca().get_legend_handles_labels()\n",
    "labels = [label_map[subcat] for subcat in subcategories]\n",
    "ax1.legend(handles[:len(subcategories)], labels)\n",
    "\n",
    "fig.set_facecolor('w')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/_DOC_flux_barplot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c1e96",
   "metadata": {},
   "source": [
    "# Unique categories and subcategories\n",
    "df = df_flux.dropna(subset=[\"flux_aCDOM412\"])\n",
    "\n",
    "categories = ['St.5B','St.4','St.MK','St.7','St.16','St.2','St.9','St.14','St.15','St.13','St.11','St.12']\n",
    "subcategories = ['GOM2021', 'GOM21FA', 'GOM22SP', 'GOM22SU']\n",
    "\n",
    "# Define custom colors\n",
    "color_map = {\n",
    "    'GOM2021': 'darkred',\n",
    "    'GOM21FA': 'blue',\n",
    "    'GOM22SP': 'green',\n",
    "    'GOM22SU': 'purple'\n",
    "}\n",
    "\n",
    "# Define custom labels (if they differ from subcategory names)\n",
    "label_map = {\n",
    "    'GOM2021': 'Summer 2021',\n",
    "    'GOM21FA': 'Fall 2021',\n",
    "    'GOM22SP': 'Spring 2022',\n",
    "    'GOM22SU': 'Summer 2022'\n",
    "}\n",
    "\n",
    "barWidth = 0.25\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(10, 8)) \n",
    "\n",
    "# Set position of bars on x axis\n",
    "r = np.arange(len(categories))\n",
    "positions = [r + i*barWidth for i in range(len(subcategories))]\n",
    "\n",
    "all_bars = []\n",
    "\n",
    "for pos, subcat in zip(positions, subcategories):\n",
    "    values = []\n",
    "    for cat in categories:\n",
    "        value = df[(df['Stn'] == cat) & (df['Camp'] == subcat)]['flux_aCDOM412'].values\n",
    "        values.append(value[0] if len(value) > 0 else 0)\n",
    "    bars = plt.bar(pos, values, width=barWidth, color=color_map[subcat], label=label_map[subcat])\n",
    "    all_bars.append(bars)\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "handles, _ = plt.gca().get_legend_handles_labels()\n",
    "labels = [label_map[subcat] for subcat in subcategories]\n",
    "plt.legend(handles[:len(subcategories)], labels)\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels\n",
    "plt.xlabel('Stations: shallow to deep')\n",
    "plt.ylabel(r'Flux of CDOM: $a_{\\mathrm{CDOM}}$ 412 (nm) $(m^{-1})$ (m$^{-2}$ day$^{-1}$)')\n",
    "plt.title('CDOM 412 flux: Benthic Chamber')\n",
    "plt.xticks(r + barWidth, categories)\n",
    "plt.ylim(-.1,.6)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "fig.set_facecolor('w')\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/CDOM412_flux_barplot.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique categories and subcategories\n",
    "df = df_flux.dropna(subset=[\"flux_aCDOM350\"])\n",
    "\n",
    "categories = ['St.5B','St.4','St.MK','St.7','St.16','St.2','St.9','St.14','St.15','St.13','St.11','St.12']\n",
    "subcategories = ['GOM2021', 'GOM21FA', 'GOM22SP', 'GOM22SU']\n",
    "\n",
    "# Define custom colors\n",
    "color_map = {\n",
    "    'GOM2021': 'darkred',\n",
    "    'GOM21FA': 'blue',\n",
    "    'GOM22SP': 'green',\n",
    "    'GOM22SU': 'purple'\n",
    "}\n",
    "\n",
    "# Define custom labels (if they differ from subcategory names)\n",
    "label_map = {\n",
    "    'GOM2021': 'Summer 2021',\n",
    "    'GOM21FA': 'Fall 2021',\n",
    "    'GOM22SP': 'Spring 2022',\n",
    "    'GOM22SU': 'Summer 2022'\n",
    "}\n",
    "\n",
    "barWidth = 0.25\n",
    "\n",
    "# Create figure with custom size\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "# Adjust the height ratios for the subplots\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[5, 1], hspace=0)  # Set hspace to 0\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "\n",
    "# Adjusted r for spacing between groups\n",
    "r = np.arange(0, len(categories) * 1.5, 1.5)\n",
    "positions = [r + i*barWidth for i in range(len(subcategories))]\n",
    "\n",
    "# Adjusted code for broken axis and added spaces between the groups\n",
    "for pos, subcat in zip(positions, subcategories):\n",
    "    values = []\n",
    "    errors = []\n",
    "    for cat in categories:\n",
    "        value = df[(df['Stn'] == cat) & (df['Camp'] == subcat)]['flux_aCDOM350'].values\n",
    "        error = df[(df['Stn'] == cat) & (df['Camp'] == subcat)]['erros_aCDOM350'].values\n",
    "        values.append(value[0] if len(value) > 0 else 0)\n",
    "        errors.append(error[0] if len(error) > 0 else 0)\n",
    "    \n",
    "    ax1.bar(pos, [v if v > 0 else 0 for v in values], width=barWidth, color=color_map[subcat],\n",
    "            label=label_map[subcat], yerr=[e if e > 0 else 0 for e in errors])\n",
    "    ax2.bar(pos, [v if v < 0 else 0 for v in values], width=barWidth, color=color_map[subcat],\n",
    "            label=label_map[subcat], yerr=[e if e > 0 else 0 for e in errors])\n",
    "\n",
    "# Setting the limit for the break\n",
    "ax1.set_ylim(0, .6)  \n",
    "ax2.set_ylim(-.1, 0)\n",
    "\n",
    "# Removing spines and ticks for the broken axis effect\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop='off')\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels\n",
    "ax2.set_xlabel('Stations: shallow to deep')\n",
    "ax1.set_ylabel(r'Flux of CDOM: $a_{\\mathrm{CDOM}}$ 350 (nm) $(m^{-1})$ (m$^{-2}$ day$^{-1}$)')\n",
    "ax1.set_title('CDOM 350 flux: Benthic Chamber')\n",
    "ax2.set_xticks(r + 1.5*barWidth)  # Adjust for the spaces between groups\n",
    "ax2.set_xticklabels(categories)\n",
    "\n",
    "# Add black horizontal line at y=0\n",
    "ax1.axhline(0, color=\"black\", linewidth=0.5)\n",
    "ax2.axhline(0, color=\"black\", linewidth=0.5)\n",
    "\n",
    "handles, _ = plt.gca().get_legend_handles_labels()\n",
    "labels = [label_map[subcat] for subcat in subcategories]\n",
    "ax1.legend(handles[:len(subcategories)], labels)\n",
    "\n",
    "fig.set_facecolor('w')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/CDOM350_flux_barplot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique categories and subcategories\n",
    "df = df_flux.dropna(subset=[\"flux_aCDOM350\"])\n",
    "\n",
    "categories = ['St.5B','St.4','St.MK','St.7','St.16','St.2','St.9','St.14','St.15','St.13','St.11','St.12']\n",
    "subcategories = ['GOM2021', 'GOM21FA', 'GOM22SP', 'GOM22SU']\n",
    "\n",
    "# Define custom colors\n",
    "color_map = {\n",
    "    'GOM2021': 'darkred',\n",
    "    'GOM21FA': 'blue',\n",
    "    'GOM22SP': 'green',\n",
    "    'GOM22SU': 'purple'\n",
    "}\n",
    "\n",
    "# Define custom labels (if they differ from subcategory names)\n",
    "label_map = {\n",
    "    'GOM2021': 'Summer 2021',\n",
    "    'GOM21FA': 'Fall 2021',\n",
    "    'GOM22SP': 'Spring 2022',\n",
    "    'GOM22SU': 'Summer 2022'\n",
    "}\n",
    "\n",
    "barWidth = 0.25\n",
    "\n",
    "# Create figure with custom size\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "# Adjust the height ratios for the subplots\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[5, 1], hspace=0)  # Set hspace to 0\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "\n",
    "# Adjusted r for spacing between groups\n",
    "r = np.arange(0, len(categories) * 1.5, 1.5)\n",
    "positions = [r + i*barWidth for i in range(len(subcategories))]\n",
    "\n",
    "# Adjusted code for broken axis and added spaces between the groups\n",
    "for pos, subcat in zip(positions, subcategories):\n",
    "    values = []\n",
    "    errors = []\n",
    "    for cat in categories:\n",
    "        value = df[(df['Stn'] == cat) & (df['Camp'] == subcat)]['flux_aCDOM350'].values\n",
    "        error = df[(df['Stn'] == cat) & (df['Camp'] == subcat)]['erros_aCDOM350'].values\n",
    "        values.append(value[0] if len(value) > 0 else 0)\n",
    "        errors.append(error[0] if len(error) > 0 else 0)\n",
    "    \n",
    "    ax1.bar(pos, [v if v > 0 else 0 for v in values], width=barWidth, color=color_map[subcat],\n",
    "            label=label_map[subcat])#, yerr=[e if e > 0 else 0 for e in errors])\n",
    "    ax2.bar(pos, [v if v < 0 else 0 for v in values], width=barWidth, color=color_map[subcat],\n",
    "            label=label_map[subcat])#, yerr=[e if e > 0 else 0 for e in errors])\n",
    "\n",
    "# Setting the limit for the break\n",
    "ax1.set_ylim(0, .04)  \n",
    "ax2.set_ylim(-.01, 0)\n",
    "\n",
    "# Removing spines and ticks for the broken axis effect\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop='off')\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels\n",
    "ax2.set_xlabel('Stations: shallow to deep')\n",
    "ax1.set_ylabel(r'Flux of CDOM: $a_{\\mathrm{CDOM}}$ 350 (nm) $(m^{-1})$ (m$^{-2}$ day$^{-1}$)')\n",
    "ax1.set_title('CDOM 350 flux: Benthic Chamber')\n",
    "ax2.set_xticks(r + 1.5*barWidth)  # Adjust for the spaces between groups\n",
    "ax2.set_xticklabels(categories)\n",
    "\n",
    "# Add black horizontal line at y=0\n",
    "ax1.axhline(0, color=\"black\", linewidth=0.5)\n",
    "ax2.axhline(0, color=\"black\", linewidth=0.5)\n",
    "\n",
    "handles, _ = plt.gca().get_legend_handles_labels()\n",
    "labels = [label_map[subcat] for subcat in subcategories]\n",
    "ax1.legend(handles[:len(subcategories)], labels)\n",
    "\n",
    "fig.set_facecolor('w')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/_CDOM350_flux_barplot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07716be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_top=30\n",
    "lat_bot=28\n",
    "lon_left=-91.5\n",
    "lon_rigth=-88.75\n",
    "extent=[lon_left, lon_rigth, lat_bot, lat_top]\n",
    "\n",
    "# set resolution of the features in map: '10m', '50m', or '110m'.  \n",
    "# If you do this the first time it will take a while downloading the coastline \n",
    "# and other features. In the future it will be faster\n",
    "res = '10m'\n",
    "\n",
    "#Figure\n",
    "\n",
    "\n",
    "def plot_mapbase(extent, res='10m', projection=ccrs.PlateCarree()):\n",
    "    fig = plt.figure(figsize=(10,5)) # set fig size\n",
    "    ax = fig.add_subplot(111, projection=projection)\n",
    "    ax.set_extent(extent)\n",
    "    ax.coastlines(res)\n",
    "    ax.add_feature(cfeature.NaturalEarthFeature(category='physical', \n",
    "                                                name='land',\n",
    "                                                facecolor='white', # change color here\n",
    "                                                scale=res)) \n",
    "    ax.add_feature(cfeature.NaturalEarthFeature(category='physical', \n",
    "                                                name='rivers_lake_centerlines',\n",
    "                                                edgecolor='blue', # change color here\n",
    "                                                facecolor='none',\n",
    "                                                scale=res))\n",
    "    gl = ax.gridlines(xlocs=np.arange(lon_left, lon_rigth+1),\n",
    "                      ylocs=np.arange(lat_bot, lat_top+1),\n",
    "                      draw_labels=True, \n",
    "                      linewidth=0.5, color='k', linestyle=':')\n",
    "    gl.top_labels = gl.right_labels = False\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_mapbase(extent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2af1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mapbase(extent, ax=None, res='10m', projection=ccrs.PlateCarree()):\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(10,5)) # set fig size\n",
    "        ax = fig.add_subplot(111, projection=projection)\n",
    "        \n",
    "    ax.set_extent(extent)\n",
    "    ax.coastlines(res)\n",
    "    ax.add_feature(cfeature.NaturalEarthFeature(category='physical', \n",
    "                                                name='land',\n",
    "                                                facecolor='white', \n",
    "                                                scale=res)) \n",
    "    ax.add_feature(cfeature.NaturalEarthFeature(category='physical', \n",
    "                                                name='rivers_lake_centerlines',\n",
    "                                                edgecolor='blue',\n",
    "                                                facecolor='none',\n",
    "                                                scale=res))\n",
    "    gl = ax.gridlines(xlocs=np.arange(lon_left, lon_rigth+1),\n",
    "                      ylocs=np.arange(lat_bot, lat_top+1),\n",
    "                      draw_labels=True, \n",
    "                      linewidth=0.5, color='k', linestyle=':')\n",
    "    gl.top_labels = gl.right_labels = False\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeaf86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique Camp values you want to plot\n",
    "camps = ['GOM2021', 'GOM21FA', 'GOM22SP', 'GOM22SU']\n",
    "\n",
    "# Find global min and max for the colormap\n",
    "vmin = -95\n",
    "vmax = 95\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "axes = axes.ravel()  # Flatten the 2x2 grid to access each subplot with a single index\n",
    "\n",
    "for i, camp in enumerate(camps):\n",
    "    df_subset = df_flux[df_flux['Camp'] == camp].dropna(subset=[\"flux_doc\"])    \n",
    "    \n",
    "    # Plot the base map for each subplot\n",
    "    plot_mapbase(extent, ax=axes[i])\n",
    "    \n",
    "    # Plotting\n",
    "    mappable = axes[i].scatter(df_subset['Lon'], df_subset['Lat'],\n",
    "                               c=df_subset['flux_doc'],\n",
    "                               edgecolor='k',\n",
    "                               cmap=cmo.curl,\n",
    "                               s=200,\n",
    "                               vmin=vmin,  # Set global min and max for colormap\n",
    "                               vmax=vmax,\n",
    "                               transform=ccrs.PlateCarree())\n",
    "    \n",
    "    # Set title for each subplot\n",
    "    axes[i].set_title(camp)\n",
    "    \n",
    "# Add a single colorbar for the entire figure\n",
    "cbar_ax = fig.add_axes([0.92, 0.3, 0.02, 0.4])\n",
    "cb = fig.colorbar(mappable, cax=cbar_ax)\n",
    "cb.set_label('DOC flux', size=10, color='black')\n",
    "cb.ax.tick_params(labelcolor='black') \n",
    "cb.ax.tick_params(labelsize=10)\n",
    "\n",
    "#plt.title(r'DOC flux:'+'\\n'+' Benthic Chamber'+'\\n')\n",
    "\n",
    "fig.set_facecolor('w')\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/Map_DOC_Flux.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285aaf1",
   "metadata": {},
   "source": [
    "# List of unique Camp values you want to plot\n",
    "camps = ['GOM2021', 'GOM21FA', 'GOM22SP', 'GOM22SU']\n",
    "\n",
    "# Find global min and max for the colormap\n",
    "vmin = -.6\n",
    "vmax = .6\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "axes = axes.ravel()  # Flatten the 2x2 grid to access each subplot with a single index\n",
    "\n",
    "for i, camp in enumerate(camps):\n",
    "    df_subset = df_flux[df_flux['Camp'] == camp].dropna(subset=[\"flux_aCDOM412\"])\n",
    "    \n",
    "    # Plot the base map for each subplot\n",
    "    plot_mapbase(extent, ax=axes[i])\n",
    "    \n",
    "    # Plotting\n",
    "    mappable = axes[i].scatter(df_subset['Lon'], df_subset['Lat'],\n",
    "                               c=df_subset['flux_aCDOM412'],\n",
    "                               edgecolor='k',\n",
    "                               cmap=cmo.diff,\n",
    "                               s=200,\n",
    "                               vmin=vmin,  # Set global min and max for colormap\n",
    "                               vmax=vmax,\n",
    "                               transform=ccrs.PlateCarree())\n",
    "    \n",
    "    # Set title for each subplot\n",
    "    axes[i].set_title(camp)\n",
    "    \n",
    "# Add a single colorbar for the entire figure\n",
    "cbar_ax = fig.add_axes([0.92, 0.3, 0.02, 0.4])\n",
    "cb = fig.colorbar(mappable, cax=cbar_ax)\n",
    "cb.set_label('a412 flux', size=10, color='black')\n",
    "cb.ax.tick_params(labelcolor='black') \n",
    "cb.ax.tick_params(labelsize=10)\n",
    "\n",
    "plt.title(r'CDOM 412 flux:'+'\\n'+' Benthic Chamber'+'\\n')\n",
    "\n",
    "fig.set_facecolor('w')\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/Map_CDOM412_Flux.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd848f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique Camp values you want to plot\n",
    "camps = ['GOM2021', 'GOM21FA', 'GOM22SP', 'GOM22SU']\n",
    "\n",
    "# Find global min and max for the colormap\n",
    "vmin = -.04\n",
    "vmax = .04\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "axes = axes.ravel()  # Flatten the 2x2 grid to access each subplot with a single index\n",
    "\n",
    "for i, camp in enumerate(camps):\n",
    "    df_subset = df_flux[df_flux['Camp'] == camp].dropna(subset=[\"flux_aCDOM350\"])\n",
    "    \n",
    "    # Plot the base map for each subplot\n",
    "    plot_mapbase(extent, ax=axes[i])\n",
    "    \n",
    "    # Plotting\n",
    "    mappable = axes[i].scatter(df_subset['Lon'], df_subset['Lat'],\n",
    "                               c=df_subset['flux_aCDOM350'],\n",
    "                               edgecolor='k',\n",
    "                               cmap=cmo.diff,\n",
    "                               s=200,\n",
    "                               vmin=vmin,  # Set global min and max for colormap\n",
    "                               vmax=vmax,\n",
    "                               transform=ccrs.PlateCarree())\n",
    "    \n",
    "    # Set title for each subplot\n",
    "    axes[i].set_title(camp)\n",
    "    \n",
    "# Add a single colorbar for the entire figure\n",
    "cbar_ax = fig.add_axes([0.92, 0.3, 0.02, 0.4])\n",
    "cb = fig.colorbar(mappable, cax=cbar_ax)\n",
    "cb.set_label('a350 flux', size=10, color='black')\n",
    "cb.ax.tick_params(labelcolor='black') \n",
    "cb.ax.tick_params(labelsize=10)\n",
    "\n",
    "#plt.title(r'CDOM 350 flux:'+'\\n'+' Benthic Chamber'+'\\n')\n",
    "\n",
    "fig.set_facecolor('w')\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/Map_CDOM350_Flux.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5829bdbd",
   "metadata": {},
   "source": [
    "# Define the camps and flux types\n",
    "camps = ['GOM2021', 'GOM21FA', 'GOM22SP', 'GOM22SU']\n",
    "flux_types = ['flux_aCDOM350', 'flux_doc']\n",
    "\n",
    "# Create a 3x4 subplot grid\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 12), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "for row, flux_type in enumerate(flux_types):\n",
    "    # Determine the global min and max for the current flux type across all camps\n",
    "    vmin = df_flux[df_flux['Camp'].isin(camps)][flux_type].min()\n",
    "    vmax = df_flux[df_flux['Camp'].isin(camps)][flux_type].max()\n",
    "    \n",
    "    for col, camp in enumerate(camps):\n",
    "        df_subset = df_flux[df_flux['Camp'] == camp].dropna(subset=[flux_type])\n",
    "        \n",
    "        mappable = axes[row, col].scatter(df_subset['Lon'], df_subset['Lat'],\n",
    "                                          c=df_subset[flux_type],\n",
    "                                          edgecolor='k',\n",
    "                                          cmap=cmo.matter,\n",
    "                                          s=100,\n",
    "                                          vmin=vmin,\n",
    "                                          vmax=vmax,\n",
    "                                          transform=ccrs.PlateCarree())\n",
    "        \n",
    "        axes[row, col].set_title(f'{camp} - {flux_type}')\n",
    "        \n",
    "        plot_mapbase(extent, ax=axes[row, col])\n",
    "\n",
    "    # Add a colorbar for each row (flux type)\n",
    "    cbar_ax = fig.add_axes([0.92, 1-(0.29*(row+1)), 0.015, 0.125])\n",
    "    cb = fig.colorbar(mappable, cax=cbar_ax)\n",
    "    cb.set_label(flux_type, size=10, color='black')\n",
    "    cb.ax.tick_params(labelcolor='black') \n",
    "    cb.ax.tick_params(labelsize=10)\n",
    "    \n",
    "fig.set_facecolor('w')\n",
    "\n",
    "plt.savefig(\"../Dissertation_projects/Figures/Flux_figures/Maps_Flux.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
